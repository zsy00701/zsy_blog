## 读survey

> [A Comprehensive Survey and Guide to Multimodal Large Language Models in Vision-Language Tasks](https://arxiv.org/pdf/2411.06284)
>
> > 梳理 MLLM 和 VLM 的架构和应用

## 读paper（基础）

MLLM基础:
● Visual Instruction Tuning   
● Qwen2.5-VL Technical Report 
● Qwen3 Technical Report
● LLaVA-OneVision: Easy Visual Task Transfer
● LLaVA-Video: Video Instruction Tuning With Synthetic Data

## 读paper（细分领域）

